<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>featurization</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html">
  <p>Featurization and Feature Engineering is the most important aspect of ML.<p>
  <h2 id="vsintro">Featurization vs Feature Engineering</h2>
  <p>Featurization is a way to change some form of data (text data, graph data, time-series data,…) into a numerical vector.<p>
  <p>
    Featurization is different from feature engineering. Feature engineering is about transforming the numerical features somehow so that they make machine
    learning models perform well at prediction. In feature engineering, features are already in the numerical form; whereas in featurization data is not need
    to be in the form of numerical vector.
  </p>
    <h2>Why Featurization?</h2>
    <p>
      At the end of the day, all our machine learning algorithm can work only with numerical (categorical, real,…) features. So it is import to change some 
      type of data into numerical vector so that we can <b>leverage the whole power of linear algebra</b> (making the decision boundary between data points)
      <b>and statistics tools</b> with other types of data also.
    </p>
    Out of the various featurization techniques available for the text data, the most commonly used techniques are :
    <ul>
        <li>Bag of Words (BOW)</li>
        <li>Term Frequency - Inverse Document Frequency (TF-IDF)</li>
        <li>Average Word2Vec</li>
        <li>TF-IDF Weighted Average Word2Vec</li>
    </ul>
   For the categorical features, the most commonly used featurization techniques are the mean response time and one-hot encoding.
   <p>
      Feature Engineering is the process of using domain knowledge to <b>extract the new variables from the raw data</b>, which makes the machine learning 
      algorithms work better. Feature Engineering is a difficult task as it is domain-specific. Feature Selection is to <b>select some useful, relevant 
      features among the features</b> we generate/find/have in our data.
   </p>
   <p>
     <b>Note :- </b>If we are using a linear model like Logistic Regression or Linear SVM, then we perform feature engineering to convert the non-linearly 
     separable data into a linearly separable format, to make our models work better. In a nutshell, we are trying to transform our features to better
     suit our models and hence design better overall models.
  </p>
  </div>
</body>
</html>

